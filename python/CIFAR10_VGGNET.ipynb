{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CIFAR10_VGGNET.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kharyal/machine-learning/blob/master/python/CIFAR10_VGGNET.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDS-3UAaZTRF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as dsets\n",
        "from torch.autograd import Variable\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FTuMTHuPZiZe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size=64\n",
        "mean = [0.4913997551666284, 0.48215855929893703, 0.4465309133731618]\n",
        "std = [0.24703225141799082, 0.24348516474564, 0.26158783926049628]\n",
        "transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize(mean,std)])\n",
        "trainset=dsets.CIFAR10(root='./data',train=True,\n",
        "                       transform=transform,\n",
        "                       download=True)\n",
        "testset=dsets.CIFAR10(root='./data',\n",
        "                      train=False,\n",
        "                     transform=transform)\n",
        "train_batch=torch.utils.data.DataLoader(dataset=trainset,\n",
        "                                       batch_size=batch_size,\n",
        "                                       shuffle=True,\n",
        "                                       num_workers=2)\n",
        "test_batch=torch.utils.data.DataLoader(dataset=testset,\n",
        "                                      batch_size=batch_size,\n",
        "                                      shuffle=False,\n",
        "                                      num_workers=2)\n",
        "classes = ('plane', 'car', 'bird', 'cat','deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-JGqbor26DEc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        },
        "outputId": "b0e74d8b-0c94-449d-9489-69434d3cc613"
      },
      "source": [
        "print(trainset.data.shape) # 50,000 images of 32*32*3 dimensions\n",
        "plt.imshow(trainset.data[129])"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 32, 32, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f0c9014ec18>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 129
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FY4F-XWfdL5i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class net(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(net,self).__init__()\n",
        "#     self.pad1=nn.ZeroPad2d()\n",
        "    self.conv1=nn.Conv2d(3,16,3,stride=1,padding=1)\n",
        "    self.conv2=nn.Conv2d(16,16,3,stride=1,padding=1)\n",
        "    self.pool1=nn.MaxPool2d(2,2)\n",
        "    self.conv3=nn.Conv2d(16,32,3,stride=1,padding=1)\n",
        "    self.conv4=nn.Conv2d(32,32,3,stride=1,padding=1)    \n",
        "    self.pool2=nn.MaxPool2d(2,2)\n",
        "    self.conv5=nn.Conv2d(32,64,3,stride=1,padding=1)    \n",
        "    self.conv6=nn.Conv2d(64,64,3,stride=1,padding=1)\n",
        "    self.pool3=nn.MaxPool2d(2,2)\n",
        "    self.conv7=nn.Conv2d(64,128,3,stride=1,padding=1)    \n",
        "    self.conv8=nn.Conv2d(128,128,3,stride=1,padding=1)\n",
        "    self.conv9=nn.Conv2d(128,256,3,stride=1,padding=1)    \n",
        "    self.pool4=nn.MaxPool2d(2,2)\n",
        "    self.conv10=nn.Conv2d(256,256,3,stride=1,padding=1)\n",
        "    self.conv11=nn.Conv2d(256,256,3,stride=1,padding=1)\n",
        "    self.fc1=nn.Linear(1024,1024)\n",
        "    self.fc2=nn.Linear(1024,1024)\n",
        "    self.fc3=nn.Linear(1024,10)\n",
        "    \n",
        "  \n",
        "  def forward(self,x):\n",
        "    x=F.relu(self.conv1(x))\n",
        "    x=F.relu(self.conv2(x))\n",
        "    x=self.pool1(x)\n",
        "    x=F.relu(self.conv3(x))\n",
        "    x=F.relu(self.conv4(x))\n",
        "    x=self.pool2(x)\n",
        "    x=F.relu(self.conv5(x))\n",
        "    x=F.relu(self.conv6(x))\n",
        "    x=self.pool3(x)\n",
        "    x=F.relu(self.conv7(x))\n",
        "    x=F.relu(self.conv8(x))\n",
        "    x=F.relu(self.conv9(x))\n",
        "    x=self.pool4(x)\n",
        "    x=F.relu(self.conv10(x))\n",
        "    x=F.relu(self.conv11(x))\n",
        "    x=x.view(-1,x.size(1) * x.size(2) * x.size(3))\n",
        "#     print(x.shape)\n",
        "    x=F.relu(self.fc1(x))\n",
        "    x=F.relu(self.fc2(x))\n",
        "    x=self.fc3(x)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-MRGsWr4OOLY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "network=net()\n",
        "if torch.cuda.is_available():\n",
        "  network.cuda()\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(network.parameters(), lr=0.0001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aMZGFUJFOnda",
        "colab_type": "code",
        "outputId": "7e9a1aab-5aec-4002-ffcd-d98693e058dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2417
        }
      },
      "source": [
        "for epoch in range(15):\n",
        "  lossTotal=0\n",
        "  for i, (images, labels) in enumerate(train_batch):\n",
        "    images=Variable(images).cuda()\n",
        "    labels=Variable(labels).cuda()\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "    op=network(images)\n",
        "    loss=loss_function(op,labels)\n",
        "    loss.backward()\n",
        "    lossTotal=lossTotal+loss.item()\n",
        "    optimizer.step()\n",
        "    if i%100 ==0:\n",
        "      print(\"local loss: \",loss.item())\n",
        "  print(\"######## end of EPOCH: \",epoch+1,\" LOSS: \",lossTotal,\" ########\")"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "local loss:  2.3036587238311768\n",
            "local loss:  2.303819417953491\n",
            "local loss:  2.190804958343506\n",
            "local loss:  2.133406639099121\n",
            "local loss:  1.951436161994934\n",
            "local loss:  1.944724440574646\n",
            "local loss:  1.8484838008880615\n",
            "local loss:  1.830869197845459\n",
            "######## end of EPOCH:  1  LOSS:  1569.990099787712  ########\n",
            "local loss:  1.8376097679138184\n",
            "local loss:  1.9327958822250366\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "170500096it [01:03, 3489960.43it/s]                               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "local loss:  1.7542519569396973\n",
            "local loss:  1.7805534601211548\n",
            "local loss:  1.7873506546020508\n",
            "local loss:  1.6381326913833618\n",
            "local loss:  1.637616753578186\n",
            "local loss:  1.617409110069275\n",
            "######## end of EPOCH:  2  LOSS:  1356.8242332935333  ########\n",
            "local loss:  1.5589333772659302\n",
            "local loss:  1.6902620792388916\n",
            "local loss:  1.4535555839538574\n",
            "local loss:  1.6993110179901123\n",
            "local loss:  1.553479552268982\n",
            "local loss:  1.6279791593551636\n",
            "local loss:  1.5442628860473633\n",
            "local loss:  1.3745492696762085\n",
            "######## end of EPOCH:  3  LOSS:  1218.3726279735565  ########\n",
            "local loss:  1.5430309772491455\n",
            "local loss:  1.3097374439239502\n",
            "local loss:  1.3320798873901367\n",
            "local loss:  1.4960345029830933\n",
            "local loss:  1.5137255191802979\n",
            "local loss:  1.5279327630996704\n",
            "local loss:  1.3226995468139648\n",
            "local loss:  1.5338917970657349\n",
            "######## end of EPOCH:  4  LOSS:  1131.1136971712112  ########\n",
            "local loss:  1.4493705034255981\n",
            "local loss:  1.5986027717590332\n",
            "local loss:  1.318633794784546\n",
            "local loss:  1.090962529182434\n",
            "local loss:  1.3383930921554565\n",
            "local loss:  1.1705024242401123\n",
            "local loss:  1.1203926801681519\n",
            "local loss:  1.0646799802780151\n",
            "######## end of EPOCH:  5  LOSS:  1045.7750290632248  ########\n",
            "local loss:  1.2213613986968994\n",
            "local loss:  1.114359974861145\n",
            "local loss:  1.1512205600738525\n",
            "local loss:  1.2860089540481567\n",
            "local loss:  1.3654180765151978\n",
            "local loss:  1.3006271123886108\n",
            "local loss:  1.5885391235351562\n",
            "local loss:  1.4544111490249634\n",
            "######## end of EPOCH:  6  LOSS:  964.3533005714417  ########\n",
            "local loss:  1.0456568002700806\n",
            "local loss:  1.0966646671295166\n",
            "local loss:  1.3368476629257202\n",
            "local loss:  1.105967402458191\n",
            "local loss:  0.9916481375694275\n",
            "local loss:  1.0855895280838013\n",
            "local loss:  1.092529535293579\n",
            "local loss:  1.055294156074524\n",
            "######## end of EPOCH:  7  LOSS:  893.3515481948853  ########\n",
            "local loss:  0.8608875870704651\n",
            "local loss:  1.1023216247558594\n",
            "local loss:  1.1399847269058228\n",
            "local loss:  1.2052515745162964\n",
            "local loss:  1.0076364278793335\n",
            "local loss:  1.2758325338363647\n",
            "local loss:  1.1199606657028198\n",
            "local loss:  0.9834715127944946\n",
            "######## end of EPOCH:  8  LOSS:  836.4470460414886  ########\n",
            "local loss:  0.8815214037895203\n",
            "local loss:  1.042147159576416\n",
            "local loss:  1.1138637065887451\n",
            "local loss:  1.064557671546936\n",
            "local loss:  1.0774388313293457\n",
            "local loss:  1.2065144777297974\n",
            "local loss:  0.9895011186599731\n",
            "local loss:  0.9918106198310852\n",
            "######## end of EPOCH:  9  LOSS:  787.412192940712  ########\n",
            "local loss:  0.9896625876426697\n",
            "local loss:  0.9751664400100708\n",
            "local loss:  1.16197669506073\n",
            "local loss:  1.1681450605392456\n",
            "local loss:  1.0150046348571777\n",
            "local loss:  0.8299317955970764\n",
            "local loss:  0.8834632039070129\n",
            "local loss:  0.9933305978775024\n",
            "######## end of EPOCH:  10  LOSS:  746.8752802610397  ########\n",
            "local loss:  1.0225555896759033\n",
            "local loss:  1.1287418603897095\n",
            "local loss:  0.8160656094551086\n",
            "local loss:  0.7303314208984375\n",
            "local loss:  0.8895748257637024\n",
            "local loss:  0.726587176322937\n",
            "local loss:  0.7484089732170105\n",
            "local loss:  0.8710694909095764\n",
            "######## end of EPOCH:  11  LOSS:  707.2292135953903  ########\n",
            "local loss:  1.1841514110565186\n",
            "local loss:  0.7728116512298584\n",
            "local loss:  0.6369092464447021\n",
            "local loss:  0.7117545008659363\n",
            "local loss:  0.6400381922721863\n",
            "local loss:  0.9053958058357239\n",
            "local loss:  0.7411181330680847\n",
            "local loss:  0.9089003205299377\n",
            "######## end of EPOCH:  12  LOSS:  671.8883946239948  ########\n",
            "local loss:  0.700403094291687\n",
            "local loss:  1.072056531906128\n",
            "local loss:  0.9062860012054443\n",
            "local loss:  0.6489980816841125\n",
            "local loss:  0.8457714319229126\n",
            "local loss:  0.8465370535850525\n",
            "local loss:  0.7079555988311768\n",
            "local loss:  0.7031527757644653\n",
            "######## end of EPOCH:  13  LOSS:  634.9975499808788  ########\n",
            "local loss:  0.6487699747085571\n",
            "local loss:  0.6801199913024902\n",
            "local loss:  0.5917323231697083\n",
            "local loss:  0.5434394478797913\n",
            "local loss:  0.928565502166748\n",
            "local loss:  0.7399016618728638\n",
            "local loss:  0.6002669930458069\n",
            "local loss:  0.8480230569839478\n",
            "######## end of EPOCH:  14  LOSS:  602.9530829489231  ########\n",
            "local loss:  0.8399210572242737\n",
            "local loss:  0.6831821203231812\n",
            "local loss:  0.7602589130401611\n",
            "local loss:  0.658649206161499\n",
            "local loss:  0.444879949092865\n",
            "local loss:  0.7189922332763672\n",
            "local loss:  0.9293676614761353\n",
            "local loss:  0.6741825938224792\n",
            "######## end of EPOCH:  15  LOSS:  574.6589286923409  ########\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ClG6iGq6YfOQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "81511fdb-cdd2-4380-ffd6-2cc29086f2e9"
      },
      "source": [
        "correct=0\n",
        "total=0\n",
        "for images,labels in test_batch:\n",
        "  images=Variable(images).cuda()\n",
        "  labels=Variable(labels).cuda()\n",
        "  \n",
        "  output = network(images)\n",
        "  _, predicted = torch.max(output,1)\n",
        "  correct += (predicted == labels).sum()\n",
        "  total += labels.size(0)\n",
        "print(\"accuracy: \",(100*correct)/(total+1))"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy:  tensor(67, device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}